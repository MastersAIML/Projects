<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.4 (456999)"/><meta name="altitude" content="888.8201293945312"/><meta name="author" content="montygupta@gmail.com"/><meta name="created" content="2018-02-13 10:55:54 +0000"/><meta name="latitude" content="12.95861159467708"/><meta name="longitude" content="77.64828156617004"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-03-05 13:18:33 +0000"/><title>Vector Analysis</title></head><body><div/><div><ol style="box-sizing: border-box; color: rgb(51, 51, 51); font-family: Merriweather, serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial;"><li style=""><a style="box-sizing: border-box; background-color: transparent; color: rgb(51, 122, 183); text-decoration: none;" target="_blank" href="http://worrydream.com/refs/Crowe-HistoryOfVectorAnalysis.pdf">The modern system of vector analysis was developed by Joseph Willard Gibbs, in the late 1800s. This history of vectors is documented brilliantly by Michael J. Crowe in this short timeline, basically the transcript of a 1967 lecture</a></li></ol></div><div><br/></div><div><br/></div><div/><div><ol style="box-sizing: border-box; color: rgb(51, 51, 51); font-family: Merriweather, serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial;"><li style=""><a style="box-sizing: border-box; background-color: transparent; color: rgb(51, 122, 183); text-decoration: none;" target="_blank" href="https://www.mathbootcamps.com/proof-every-matrix-transformation-is-a-linear-transformation/">Formal proof that every matrix operation is a linear transformation</a></li><li style=""><a style="box-sizing: border-box; background-color: transparent; color: rgb(51, 122, 183); text-decoration: none;" target="_blank" href="https://www.khanacademy.org/math/precalculus/precalc-matrices/row-echelon-and-gaussian-elimination/v/matrices-reduced-row-echelon-form-2">In-depth video on how to use the row-echelon form to manually solve a system of linear equations.</a></li></ol></div><div><br/></div><div><br/></div><div><h2 style="box-sizing: border-box; font-family: Lato, sans-serif; font-weight: 300 !important; color: rgb(155, 155, 155); font-size: 26px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial;">Linear Independence in Data Vectors: Multicollinearity
</h2><br/></div><div><span style="color: rgb(51, 51, 51); font-family: Merriweather, serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial; float: none;">An application where Eigenvalues and Eigenvectors are most commonly used is Principal Component Analysis (PCA). You will learn about PCA in detail later in the program.</span><br/></div><div><span style="color: rgb(51, 51, 51); font-family: Merriweather, serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial; float: none;"><br/></span></div><div><span style="color: rgb(51, 51, 51); font-family: Merriweather, serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial; float: none;"><p style="box-sizing: border-box; font-size: 16px; font-weight: 300; word-wrap: break-word; color: rgb(51, 51, 51); font-family: Merriweather, serif; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial;">In general, the steps followed in PCA are as follows:
</p><div/><ol style="box-sizing: border-box; color: rgb(51, 51, 51); font-family: Merriweather, serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); text-decoration-style: initial; text-decoration-color: initial;"><li style="box-sizing: border-box;">Standardise the data.</li><li style="box-sizing: border-box;">Use the standardised data to create a covariance matrix.</li><li style="box-sizing: border-box;">Use the resulting matrix to calculate eigenvectors (principal components) and their corresponding eigenvalues.</li><li style="box-sizing: border-box;">Sort the components in decending order by its eigenvalue.</li><li style="box-sizing: border-box;">Choose <em style="box-sizing: border-box;">n</em> components which explain the most variance within the data (larger eigenvalue means the feature explains more variance).</li><li style="box-sizing: border-box;">Create a new matrix using the <em style="box-sizing: border-box;">n</em> components.</li></ol><br/></span></div><div><br/></div></body></html>