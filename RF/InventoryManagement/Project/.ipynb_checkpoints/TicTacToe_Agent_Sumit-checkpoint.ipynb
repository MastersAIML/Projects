{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rznSDgbvGggG"
   },
   "source": [
    "## Tic-Tac-Toe Agent\n",
    "â€‹\n",
    "In this notebook, you will learn to build an RL agent (using Q-learning) that learns to play Numerical Tic-Tac-Toe with odd numbers. The environment is playing randomly with the agent, i.e. its strategy is to put an even number randomly in an empty cell. The following is the layout of the notebook:\n",
    "        - Defining epsilon-greedy strategy\n",
    "        - Tracking state-action pairs for convergence\n",
    "        - Define hyperparameters for the Q-learning algorithm\n",
    "        - Generating episode and applying Q-update equation\n",
    "        - Checking convergence in Q-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eDb8PxBGggH"
   },
   "source": [
    "#### Importing libraries\n",
    "Write the code to import Tic-Tac-Toe class from the environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SFNYceFGggJ"
   },
   "outputs": [],
   "source": [
    "# from <TC_Env> import <TicTacToe> - import your class from environment file\n",
    "from TCGame_Env1 import TicTacToe\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYLQyopEG8nz"
   },
   "outputs": [],
   "source": [
    "# Function to convert state array into a string to store it as keys in the dictionary\n",
    "# states in Q-dictionary will be of form: x-4-5-3-8-x-x-x-x\n",
    "#   x | 4 | 5\n",
    "#   ----------\n",
    "#   3 | 8 | x\n",
    "#   ----------\n",
    "#   x | x | x\n",
    "\n",
    "def Q_state(state):\n",
    "\n",
    "    return ('-'.join(str(e) for e in state)).replace('nan','x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZebMOoiVHBBr"
   },
   "outputs": [],
   "source": [
    "# Defining a function which will return valid (all possible actions) actions corresponding to a state\n",
    "# Important to avoid errors during deployment.\n",
    "\n",
    "def valid_actions(state):\n",
    "\n",
    "    valid_Actions = []\n",
    "    \n",
    "    valid_Actions = [i for i in env.action_space(state)[0]] ###### -------please call your environment as env\n",
    "    return valid_Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRciPUkYHDWf"
   },
   "outputs": [],
   "source": [
    "# Defining a function which will add new Q-values to the Q-dictionary. \n",
    "def add_to_dict(state):\n",
    "    state1 = Q_state(state)\n",
    "    \n",
    "    valid_act = valid_actions(state)\n",
    "    if state1 not in Q_dict.keys():\n",
    "        for action in valid_act:\n",
    "            Q_dict[state1][action]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNNi_EfHGggM"
   },
   "source": [
    "#### Epsilon-greedy strategy - Write your code here\n",
    "\n",
    "(you can build your epsilon-decay function similar to the one given at the end of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0lMfqiJGggN"
   },
   "outputs": [],
   "source": [
    "# Defining epsilon-greedy policy. You can choose any function epsilon-decay strategy\n",
    "\n",
    "def epsilon_greedy(state, time):\n",
    "    max_epsilon = 1.0\n",
    "    min_epsilon = 0.001\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-0.000001*time)\n",
    "\n",
    "    z = np.random.random()\n",
    "    state1 = Q_state(state)\n",
    "    if z > epsilon:\n",
    "        action = max(Q_dict[state1],key=Q_dict[state1].get)   #Exploitation: this gets the action corresponding to max q-value of current state\n",
    "    else:\n",
    "        agent_actions, env_actions =  env.action_space(state) #randomly choosing an action\n",
    "        # Converting to a list to get a random action from the possible actions\n",
    "        list_agent_actions = list(agent_actions)\n",
    "        action = tuple(list_agent_actions[random.randint(0,len(list_agent_actions) - 1)])\n",
    "    return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2kyQHOMGggR"
   },
   "source": [
    "#### Tracking the state-action pairs for checking convergence - write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcxZ29vdGggS"
   },
   "outputs": [],
   "source": [
    "# Initialise Q_dictionary as 'Q_dict' and States_tracked as 'States_track' (for convergence)\n",
    "\n",
    "Q_dict = collections.defaultdict(dict)\n",
    "\n",
    "States_track = collections.defaultdict(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vs73iv8fHOxV"
   },
   "outputs": [],
   "source": [
    "# Initialise states to be tracked\n",
    "def initialise_tracking_states():\n",
    "    # The states and actions should convege for the 2nd action from the agent\n",
    "    sample_q_values = [('1-x-x-2-x-x-x-x-x',(2,7)),('1-2-x-x-x-x-x-x-x',(4,9)),('x-4-5-x-x-x-x-x-x',(8,3)),('x-x-x-3-8-x-x-x-x',(7,5))]\n",
    "    for q_values in sample_q_values:\n",
    "        state = q_values[0]\n",
    "        action = q_values[1]\n",
    "        States_track[state][action] = \"0\"   #this is an array which will have appended values of that state-action pair for every 2000th episode           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAbwJDMVHpwl"
   },
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Pyj7nMVHsBi"
   },
   "outputs": [],
   "source": [
    "def save_tracking_states():\n",
    "    for state in States_track.keys():\n",
    "        for action in States_track[state].keys():\n",
    "            if state in Q_dict and action in Q_dict[state]:\n",
    "                States_track[state][action].append(str(Q_dict[state][action]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_8xSluUHvew"
   },
   "outputs": [],
   "source": [
    "initialise_tracking_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iPt--E9GggV"
   },
   "source": [
    "#### Define hyperparameters  ---write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0_f5czFGggW"
   },
   "outputs": [],
   "source": [
    "EPISODES = 15000\n",
    "#EPISODES = 15000000\n",
    "LR = 0.01                   #learning rate\n",
    "GAMMA = 0.91\n",
    "\n",
    "\n",
    "#threshold = 2000       #every these many episodes, the 4 Q-values will be stored/appended (convergence graphs)\n",
    "threshold = 200\n",
    "#policy_threshold = 30000    #every these many episodes, the Q-dict will be updated\n",
    "policy_threshold = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Md6twJ7wGggh"
   },
   "source": [
    "### Q-update loop ---write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldCgQuDNGggj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.01\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.0199\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] 0\n",
      "States_track[state][action] -0.029701\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    ##### Start writing your code from the next line\n",
    "    \n",
    "    env = TicTacToe()      #creating an instance of TicTacToe\n",
    "    \n",
    "    initial_state = env.state    #for the purpose of tracking reward\n",
    "    curr_state = env.state     \n",
    "    \n",
    "    add_to_dict(curr_state)\n",
    "    \n",
    "    time_step = 0\n",
    "    status = False\n",
    "    reward = None\n",
    "    total_reward = 0  \n",
    "    \n",
    "    while status == False:    #the episode will run only till the TicTacToe game is not over\n",
    "           \n",
    "        curr_action = epsilon_greedy(curr_state, time_step)\n",
    "        next_state, reward, status = env.step(curr_state, curr_action)\n",
    "        \n",
    "        add_to_dict(next_state)\n",
    "        \n",
    "        next_dict_state = Q_state(next_state)\n",
    " \n",
    "        if (Q_dict[next_dict_state]):                \n",
    "            # UPDATE RULE\n",
    "            max_next = max(Q_dict[next_dict_state],key=Q_dict[next_dict_state].get) #this gets the action corresponding to max q-value of next state\n",
    "            Q_dict[Q_state(curr_state)][curr_action] += LR * ((reward + (GAMMA*(Q_dict[Q_state(next_state)][max_next]))) - Q_dict[Q_state(curr_state)][curr_action])\n",
    "            curr_state = next_state       #state(t) became state(t-1)\n",
    "\n",
    "            total_reward += reward\n",
    "        \n",
    "        time_step += 1\n",
    " \n",
    "    \n",
    "    #TRACKING Q-VALUES\n",
    "    if (episode == threshold-1):       \n",
    "        initialise_tracking_states()\n",
    "      \n",
    "    if ((episode+1) % threshold) == 0:   \n",
    "        save_tracking_states()\n",
    "        save_obj(States_track,'States_tracked')   \n",
    "    \n",
    "    #SAVING POLICY\n",
    "    if ((episode+1)% policy_threshold ) == 0:  \n",
    "        save_obj(Q_dict,'Policy')    \n",
    " \n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "save_obj(States_track,'States_tracked')   \n",
    "save_obj(Q_dict,'Policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhdWewc4Gggo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8LfSgVuHGggu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6eMFbb8Ggg2"
   },
   "source": [
    "#### Check the Q-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr9d2fcVGgg4"
   },
   "outputs": [],
   "source": [
    "# Q_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1tnDJWkGgg9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99016"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFgUqfcQGghB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): -0.01,\n",
       " (0, 5): -0.10900000000000001,\n",
       " (0, 7): 0,\n",
       " (0, 9): -0.01,\n",
       " (1, 1): -0.01,\n",
       " (1, 5): -0.01,\n",
       " (1, 7): 0,\n",
       " (1, 9): -0.01,\n",
       " (2, 1): -0.01,\n",
       " (2, 5): -0.1,\n",
       " (2, 7): 0,\n",
       " (2, 9): 0,\n",
       " (5, 1): -0.01,\n",
       " (5, 5): 0,\n",
       " (5, 7): -0.0199,\n",
       " (5, 9): -0.01,\n",
       " (6, 1): 0,\n",
       " (6, 5): -0.1,\n",
       " (6, 7): -0.01,\n",
       " (6, 9): 0,\n",
       " (7, 1): 0,\n",
       " (7, 5): -0.029701,\n",
       " (7, 7): -0.01,\n",
       " (7, 9): 0,\n",
       " (8, 1): -0.1,\n",
       " (8, 5): -0.01,\n",
       " (8, 7): 0,\n",
       " (8, 9): 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try checking for one of the states - that which action your agent thinks is the best  -----This will not be evaluated\n",
    "#print ('State: 1-2-4-5-x-x-x-x-x')\n",
    "#print (Q_dict['1-2-4-5-x-x-x-x-x'])\n",
    "#print ('State: x-4-5-3-8-x-x-x-x')\n",
    "#print (Q_dict['x-4-5-3-8-x-x-x-x'])\n",
    "#print ('State: 1-2-3-4-x-x-x-x-x')\n",
    "#print (Q_dict['1-2-3-4-x-x-x-x-x'])\n",
    "#print ('State: 1-x-x-2-5-4-x-x-x')\n",
    "#print (Q_dict['1-x-x-2-5-4-x-x-x'])\n",
    "Q_dict['1-x-x-2-x-x-x-x-x']\n",
    "Q_dict['1-2-x-x-x-x-x-x-x']\n",
    "Q_dict['x-4-5-x-x-x-x-x-x']\n",
    "Q_dict['x-x-x-3-8-x-x-x-x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGPZEQDFGghG"
   },
   "source": [
    "#### Check the states tracked for Q-values convergence\n",
    "(non-evaluative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9s1Tvz8HGghH"
   },
   "outputs": [],
   "source": [
    "# Write the code for plotting the graphs for state-action pairs tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVQInsg7GghL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10cce6048>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a3eac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('States_tracked.pkl', 'rb') as handle:\n",
    "    States_track = pickle.load(handle)  \n",
    "print(len(States_track))\n",
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('state=(x-x-x-3-8-x-x-x-x) action=(7,5)')\n",
    "xaxis = np.asarray(range(0, 1))\n",
    "plt.plot(xaxis,np.asarray(States_track[('x-x-x-3-8-x-x-x-x')][(7,5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2Opp8_NITkC"
   },
   "source": [
    "### Epsilon - decay check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQ_D_JsuGghR"
   },
   "outputs": [],
   "source": [
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.001\n",
    "time = np.arange(0,5000000)\n",
    "epsilon = []\n",
    "for i in range(0,5000000):\n",
    "    epsilon.append(min_epsilon + (max_epsilon - min_epsilon) * np.exp(-0.000001*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "J7c2xADQGghV",
    "outputId": "cb60fce3-570b-45fb-bd83-abde3d13b273"
   },
   "outputs": [],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59BRf43IJiQ1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TicTacToe_Agent.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
